# -*- coding: utf-8 -*-
"""Consistency-Based SSS + Strong-weak Augs.ipynb

Automatically generated by Colab.

# 1. Setting up the Enivronment
"""

#mount drive
from google.colab import drive
drive.mount('/content/drive')

#install dependencies
!pip install -q torch torchvision
!pip install -q segmentation-models-pytorch
!pip install -q tensorboard
!pip install -q pyyaml
!pip install -q opencv-python
!pip install -q matplotlib

"""# 2. Dataset Configuration and Verification"""

DATA_ROOT = "/content/drive/MyDrive/aircraft_voc"

#verifying dataset structure
import os
from pathlib import Path

def verify_dataset_structure(data_root):
    required_dirs = [
        'JPEGImages',
        'SegmentationClass',
        'ImageSets/Segmentation'
    ]

    all_exist = True

    for dir_path in required_dirs:
        full_path = os.path.join(data_root, dir_path)
        exists = os.path.exists(full_path)

        if exists:
            # Count files
            if os.path.isdir(full_path):
                num_files = len([f for f in os.listdir(full_path) if os.path.isfile(os.path.join(full_path, f))])
                print(f"  {dir_path}: {num_files} files")
        else:
            print(f" {dir_path} is NOT FOUND")
            all_exist = False

    return all_exist

dataset_valid = verify_dataset_structure(DATA_ROOT)

if not dataset_valid:
    print("\n Something wrong")
else:
    print("\n Dataset all good")

"""#3. Create UNet++ with MobileNetV2"""

#create junior UNet++ model
unetpp_model_code = '''import torch
import torch.nn as nn
import torch.nn.functional as F
import segmentation_models_pytorch as smp

class UNetPlusPlus(nn.Module):
    #UNet++ model with MobileNetV2 encoder for semantic segmentation

    def __init__(self, num_classes, encoder_name='mobilenet_v2', pretrained=True):
        super(UNetPlusPlus, self).__init__()

        self.num_classes = num_classes
        self.encoder_name = encoder_name

        #creation of UNet++ model with MobileNetV2 encoder
        self.backbone = smp.UnetPlusPlus(
            encoder_name=encoder_name,
            encoder_weights='imagenet' if pretrained else None,
            in_channels=3,
            classes=num_classes,
            activation=None,  #no activation, return logits
        )

    def forward(self, x, need_fp=False):
           # x: input tensor [B, 3, H, W]
           # need_fp: whether to return feature maps (for consistency regularization)
        #Returns:
            #logits [B, num_classes, H, W] or (logits, features) if need_fp
        # Get output from UNet++
        out = self.backbone(x)

        if need_fp:
            # Use the output as feature representation for consistency loss
            return out, out

        return out

    def decode(self, features):
        return features

def UNetPlusPlusMobileNetV2(num_classes, pretrained=True):
    return UNetPlusPlus(num_classes=num_classes, encoder_name='mobilenet_v2', pretrained=pretrained)
'''

#writing UNet++ model to file
os.makedirs('/content/my_project/model/semseg', exist_ok=True)
with open('/content/my_project/model/semseg/unetplusplus.py', 'w') as f:
    f.write(unetpp_model_code)

print("Created UNet++ model file: model/semseg/unetplusplus.py")
print("  Encoder: MobileNetV2 (lightweight and efficient)")
print("  Decoder: UNet++ nested skip connections")

"""# 5. Create Semi-Supervised Training Script"""

#comprehensive semi-supervised training script
training_script = f'''#!/usr/bin/env python3

#config 1 of Semi-Supervised Training UNet++ only implements Pseudo-labeling with confidence thresholding

import argparse
import os
import random

import numpy as np
import torch
from torch import nn
from torch.optim import SGD, Adam
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import torchvision.transforms as T
import albumentations as A
from albumentations.pytorch import ToTensorV2
import sys

sys.path.insert(0, '/content/my_project')

from model.semseg.unetplusplus import UNetPlusPlusMobileNetV2
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler #mixed precision training

DATA_ROOT = "{DATA_ROOT}"
NUM_CLASSES = 2

# Simple logger and utility classes
class SimpleLogger:
    def __init__(self, name):
        self.name = name

    def info(self, msg):
        print(f"[INFO] {{msg}}")

class AverageMeter:
    """Computes and stores the average and current value"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

def dice_loss(preds, targets, smooth=1e-6):
    #Dice loss for binary segmentation matching our crack detection pipeline EXACTLY
    probs = torch.softmax(preds, dim=1)[:, 1, :, :]  #class 1 (crack)
    targets = (targets == 1).float()

    probs = probs.contiguous().view(-1)
    targets = targets.contiguous().view(-1)

    intersection = (probs * targets).sum()
    dice = (2. * intersection + smooth) / (probs.sum() + targets.sum() + smooth)

    return 1 - dice

def compute_metrics(pred, target, num_classes=2, ignore_index=255):
    pred = pred.flatten()
    target = target.flatten()

    # Filter out ignore index
    valid_mask = (target != ignore_index)
    pred = pred[valid_mask]
    target = target[valid_mask]

    metrics = {{}}

    #per-class metrics
    ious = []
    dices = []
    precisions = []
    recalls = []

    for cls in range(num_classes):
        pred_cls = (pred == cls)
        target_cls = (target == cls)

        #True Positives, False Positives, False Negatives
        tp = (pred_cls & target_cls).sum().float()
        fp = (pred_cls & ~target_cls).sum().float()
        fn = (~pred_cls & target_cls).sum().float()

        #IoU
        union = tp + fp + fn
        iou = tp / (union + 1e-8)
        ious.append(iou.item())

        #Dice
        dice = (2 * tp) / (2 * tp + fp + fn + 1e-8)
        dices.append(dice.item())

        #Precision
        precision = tp / (tp + fp + 1e-8)
        precisions.append(precision.item())

        #Recall
        recall = tp / (tp + fn + 1e-8)
        recalls.append(recall.item())

    #Accuracy
    accuracy = (pred == target).float().mean().item()

    metrics['iou'] = np.mean(ious)
    metrics['dice'] = np.mean(dices)
    metrics['accuracy'] = accuracy
    metrics['precision'] = np.mean(precisions)
    metrics['recall'] = np.mean(recalls)

    return metrics

def validate(model, dataloader, device, num_classes):
    model.eval()
    all_metrics = {{'iou': [], 'dice': [], 'accuracy': [], 'precision': [], 'recall': []}}

    with torch.no_grad():
        for images, masks in dataloader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            preds = outputs.argmax(dim=1)

            batch_metrics = compute_metrics(preds, masks, num_classes)
            for k in all_metrics:
                all_metrics[k].append(batch_metrics[k])

    return {{k: np.mean(v) for k, v in all_metrics.items()}}

def parse_args():
    parser = argparse.ArgumentParser(description='Semi-Supervised Semantic Segmentation')
    parser.add_argument('--config', type=str, default='configs/aircraft.yaml')
    parser.add_argument('--labeled-id-path', type=str, default='splits/aircraft/labeled.txt')
    parser.add_argument('--unlabeled-id-path', type=str, default='splits/aircraft/unlabeled.txt')
    parser.add_argument('--save-path', type=str, default='exp/aircraft_unetpp')
    parser.add_argument('--local_rank', type=int, default=0)
    parser.add_argument('--port', default=None, type=int)

    args = parser.parse_args([])  # Empty list for Colab
    return args

def create_split_files(data_root, labeled_ratio=0.1):
    """Create labeled/unlabeled splits for semi-supervised learning"""
    import random

    #Read all training images
    train_file = os.path.join(data_root, 'ImageSets/Segmentation/train.txt')

    with open(train_file, 'r') as f:
        all_ids = [line.strip() for line in f.readlines()]

    if len(all_ids) == 0:
        print("Error: No image IDs found in train file!")
        return False

    # Shuffle and split
    random.shuffle(all_ids)
    num_labeled = max(1, int(len(all_ids) * labeled_ratio))
    labeled_ids = all_ids[:num_labeled]
    unlabeled_ids = all_ids[num_labeled:]

    # Create split directory
    os.makedirs('splits/aircraft', exist_ok=True)

    # Save splits
    with open('splits/aircraft/labeled.txt', 'w') as f:
        f.write('\\n'.join(labeled_ids))

    with open('splits/aircraft/unlabeled.txt', 'w') as f:
        f.write('\\n'.join(unlabeled_ids))

    print(f" Created splits: {{num_labeled}} labeled, {{len(unlabeled_ids)}} unlabeled")
    print(f"  Labeled ratio: {{labeled_ratio*100:.1f}}%")

    return True

def get_default_config():
    """Default configuration for training. Matching our aircraft crack pipeline"""
    return {{
        'dataset': 'aircraft',
        'data_root': DATA_ROOT,
        'batch_size': 4,
        'lr': 0.0005,  # max_lr
        'min_lr': 0.000001,
        'epochs': 40,
        'crop_size': 512,
        'backbone': 'unetplusplus',
        'num_classes': NUM_CLASSES,

        # Semi-supervised settings
        'labeled_ratio': 0.7,
        'unsup_weight': 1.0,
        'pseudo_threshold': 0.95,
        'use_strong_aug': True,

        # Optimizer
        'optimizer': 'adam',
        'momentum': 0.9,
        'weight_decay': 0,
        'lr_decay_type': 'cos',

        # Training settings
        'num_workers': 4,
        'mixed_precision': True,  # 16-bit AMP
        'sync_bn': True,

        # Early stopping
        'early_stopping': True,
        'patience': 10,
        'monitor': 'val_dice',  # Monitor dice score

        # Logging
        'print_interval': 10,
        'eval_interval': 1,  # Validate every epoch
        'save_period': 20,
    }}

class SimpleDataset(Dataset):
    #Dataset with augmentations matching our pipeline EXACTLY"""
    def __init__(self, data_root, split_file, phase='train', size=512):
        self.data_root = data_root
        self.phase = phase
        self.size = size

        with open(split_file, 'r') as f:
            self.ids = [line.strip() for line in f.readlines()]

        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]

        if phase == 'train':
            self.transform = A.Compose([
                A.RandomScale(scale_limit=0.5, p=0.5),
                A.Rotate(limit=10, p=0.5),
                A.HorizontalFlip(p=0.5),
                A.VerticalFlip(p=0.3),
                A.Resize(size, size),
                A.Normalize(mean=mean, std=std),
                ToTensorV2()
            ])
        else:
            self.transform = A.Compose([
                A.Resize(size, size),
                A.Normalize(mean=mean, std=std),
                ToTensorV2()
            ])

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        img_id = self.ids[idx]

        #Load image
        img_path = os.path.join(self.data_root, 'JPEGImages', f"{{img_id}}.jpg")
        if not os.path.exists(img_path):
            img_path = os.path.join(self.data_root, 'JPEGImages', f"{{img_id}}.png")
        img = Image.open(img_path).convert('RGB')

        #Load mask
        mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{{img_id}}.png")
        if not os.path.exists(mask_path):
            mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{{img_id}}.jpg")
        mask = Image.open(mask_path)

        #IMP FIX: Resize BEFORE converting to numpy for same dimensions
        img = img.resize((self.size, self.size), Image.BILINEAR)
        mask = mask.resize((self.size, self.size), Image.NEAREST)

        #Convert to numpy for Albumentations
        img = np.array(img)
        mask = np.array(mask)

        #Apply transforms (for both image and mask)
        augmented = self.transform(image=img, mask=mask)
        img = augmented['image']
        mask = augmented['mask'].long()

        return img, mask

def main():
    args = parse_args()
    cfg = get_default_config()

    #Setup logging
    os.makedirs(args.save_path, exist_ok=True)
    logger = SimpleLogger('global')

    #Set random seed
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)
    torch.cuda.manual_seed_all(42)

    # Create labeled/unlabeled splits
    print("\\nCreating semi-supervised data splits...")
    if not create_split_files(DATA_ROOT, labeled_ratio=cfg['labeled_ratio']):
        print("Error creating splits!")
        return

    #Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\\nUsing device: {{device}}")

    #Create model
    print("\\nCreating UNet++ model with MobileNetV2 encoder...")
    model = UNetPlusPlusMobileNetV2(num_classes=NUM_CLASSES, pretrained=True)
    model = model.to(device)

    #Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    print(f"  Total parameters: {{total_params:,}}")

    #Optimizer
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=cfg['lr'],
        weight_decay=cfg['weight_decay']
    )

    # Learning rate scheduler
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=cfg['epochs'],
        eta_min=cfg['min_lr']
    )

    # Loss functions. HYBRID LOSS like our pipeline
    criterion_ce = nn.CrossEntropyLoss(ignore_index=255).to(device)  # CrossEntropy
    criterion_u = nn.CrossEntropyLoss(ignore_index=255, reduction='none').to(device)

    # Mixed precision training scaler
    scaler = GradScaler() if cfg['mixed_precision'] else None

    # Load datasets
    print(f"\\nLoading datasets from {{DATA_ROOT}}...")

    trainset_l = SimpleDataset(DATA_ROOT, 'splits/aircraft/labeled.txt', phase='train', size=cfg['crop_size'])
    trainset_u = SimpleDataset(DATA_ROOT, 'splits/aircraft/unlabeled.txt', phase='train', size=cfg['crop_size'])

    trainloader_l = DataLoader(trainset_l, batch_size=cfg['batch_size'],
                               shuffle=True, num_workers=cfg['num_workers'], drop_last=True, pin_memory=True)
    trainloader_u = DataLoader(trainset_u, batch_size=cfg['batch_size'],
                               shuffle=True, num_workers=cfg['num_workers'], drop_last=True, pin_memory=True)

    print(f"  Labeled samples: {{len(trainset_l)}}")
    print(f"  Unlabeled samples: {{len(trainset_u)}}")

    #Training loop
    print(f"\\nStarting semi-supervised training for {{cfg['epochs']}} epochs...")
    print(f"Mixed Precision: {{cfg['mixed_precision']}}")
    print(f"Early Stopping: {{cfg['early_stopping']}} (patience={{cfg['patience']}})")
    print("=" * 80)

    best_loss = float('inf')
    best_dice = 0.0
    patience_counter = 0

    for epoch in range(cfg['epochs']):
        model.train()

        losses_l = AverageMeter()
        losses_u = AverageMeter()
        losses_total = AverageMeter()

        loader_l_iter = iter(trainloader_l)
        loader_u_iter = iter(trainloader_u)

        num_batches = min(len(trainloader_l), len(trainloader_u))

        for i in range(num_batches):
            # Get labeled batch
            try:
                img_l, mask_l = next(loader_l_iter)
            except StopIteration:
                loader_l_iter = iter(trainloader_l)
                img_l, mask_l = next(loader_l_iter)

            # Get unlabeled batch
            try:
                img_u, _ = next(loader_u_iter)
            except StopIteration:
                loader_u_iter = iter(trainloader_u)
                img_u, _ = next(loader_u_iter)

            img_l, mask_l = img_l.to(device), mask_l.to(device)
            img_u = img_u.to(device)

            optimizer.zero_grad()

            # Mixed precision training
            if cfg['mixed_precision']:
                with autocast():
                    # Forward pass on labeled data with HYBRID LOSS
                    pred_l = model(img_l)
                    ce_loss = criterion_ce(pred_l, mask_l)
                    d_loss = dice_loss(pred_l, mask_l)
                    loss_l = ce_loss + 0.5 * d_loss  # HYBRID: CE + 0.5*Dice

                    # Forward pass on unlabeled data (pseudo-labeling)
                    with torch.no_grad():
                        pred_u = model(img_u)
                        prob_u = F.softmax(pred_u, dim=1)
                        conf_u, pseudo_u = torch.max(prob_u, dim=1)
                        mask_u = (conf_u >= cfg['pseudo_threshold']).float()

                    # Supervised loss on pseudo-labels
                    pred_u_strong = model(img_u)
                    loss_u = criterion_u(pred_u_strong, pseudo_u)
                    loss_u = (loss_u * mask_u).sum() / (mask_u.sum() + 1e-8)

                    # Total loss
                    loss = loss_l + cfg['unsup_weight'] * loss_u

                # Backward with gradient scaling
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                #Standard training (no mixed precision) with HYBRID LOSS
                pred_l = model(img_l)
                ce_loss = criterion_ce(pred_l, mask_l)
                d_loss = dice_loss(pred_l, mask_l)
                loss_l = ce_loss + 0.5 * d_loss  # HYBRID: CE + 0.5*Dice

                with torch.no_grad():
                    pred_u = model(img_u)
                    prob_u = F.softmax(pred_u, dim=1)
                    conf_u, pseudo_u = torch.max(prob_u, dim=1)
                    mask_u = (conf_u >= cfg['pseudo_threshold']).float()

                pred_u_strong = model(img_u)
                loss_u = criterion_u(pred_u_strong, pseudo_u)
                loss_u = (loss_u * mask_u).sum() / (mask_u.sum() + 1e-8)

                loss = loss_l + cfg['unsup_weight'] * loss_u

                loss.backward()
                optimizer.step()

            #Update metrics
            losses_l.update(loss_l.item())
            losses_u.update(loss_u.item())
            losses_total.update(loss.item())

            if (i + 1) % cfg['print_interval'] == 0:
                print(f"Epoch [{{epoch+1}}/{{cfg['epochs']}}] "
                      f"Iter [{{i+1}}/{{num_batches}}] "
                      f"Loss: {{losses_total.avg:.4f}} "
                      f"(L: {{losses_l.avg:.4f}}, U: {{losses_u.avg:.4f}})")

        # Validation phase
        if (epoch + 1) % cfg['eval_interval'] == 0:
            model.eval()
            val_metrics = validate(model, trainloader_l, device, cfg['num_classes'])
            model.train()

            print(f"\\nEpoch {{epoch+1}} completed:")
            print(f"  Train Loss: {{losses_total.avg:.4f}} (Labeled: {{losses_l.avg:.4f}}, Unlabeled: {{losses_u.avg:.4f}})")
            print(f"  Val IoU: {{val_metrics['iou']:.4f}}")
            print(f"  Val Dice: {{val_metrics['dice']:.4f}}")
            print(f"  Val Accuracy: {{val_metrics['accuracy']:.4f}}")
            print(f"  Val Precision: {{val_metrics['precision']:.4f}}")
            print(f"  Val Recall: {{val_metrics['recall']:.4f}}")
            print(f"  Learning Rate: {{optimizer.param_groups[0]['lr']:.6f}}")

            # Save best model based on dice score
            if val_metrics['dice'] > best_dice:
                best_dice = val_metrics['dice']
                patience_counter = 0
                checkpoint = {{
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'dice': best_dice,
                    'loss': losses_total.avg,
                }}
                torch.save(checkpoint, os.path.join(args.save_path, f'best_model_dice={{best_dice:.2f}}.pth'))
                print(f"  Saved best model (dice: {{best_dice:.4f}})")
            else:
                patience_counter += 1
                print(f"  No improvement (patience: {{patience_counter}}/{{cfg['patience']}})")

            # Early stopping
            if cfg['early_stopping'] and patience_counter >= cfg['patience']:
                print(f"\\n  Early stopping triggered! No improvement for {{cfg['patience']}} epochs.")
                break

        # Step the learning rate scheduler
        scheduler.step()

        # Periodic checkpoint saving
        if (epoch + 1) % cfg['save_period'] == 0:
            checkpoint = {{
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'loss': losses_total.avg,
            }}
            torch.save(checkpoint, os.path.join(args.save_path, f'epoch_{{epoch+1}}.pth'))
            print(f"  Saved periodic checkpoint: epoch_{{epoch+1}}.pth")

        print("=" * 80)

    print("\\n Training complete!")
    print(f"Best loss: {{best_loss:.4f}}")
    print(f"Model saved to: {{args.save_path}}/best_model.pth")

if __name__ == '__main__':
    main()
'''

with open('/content/my_project/train_semi.py', 'w') as f:
    f.write(training_script)

print(" Created semi-supervised training script: train_semi.py")

"""# 6. Evaluation"""

eval_script = f'''#!/usr/bin/env python3
"""
Evaluation script for trained UNet++ model
"""

import os
import sys
import torch
import numpy as np
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import torchvision.transforms as T
from tqdm import tqdm
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

sys.path.insert(0, '/content/my_project')
from model.semseg.unetplusplus import UNetPlusPlusMobileNetV2

DATA_ROOT = "{DATA_ROOT}"
NUM_CLASSES = 2
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class EvalDataset(Dataset):
    def __init__(self, data_root, split_file, transform=None, size=512):
        self.data_root = data_root
        self.transform = transform
        self.size = size

        with open(split_file, 'r') as f:
            self.ids = [line.strip() for line in f.readlines()]

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        img_id = self.ids[idx]

        # Load image
        img_path = os.path.join(self.data_root, 'JPEGImages', f"{{img_id}}.jpg")
        if not os.path.exists(img_path):
            img_path = os.path.join(self.data_root, 'JPEGImages', f"{{img_id}}.png")
        img = Image.open(img_path).convert('RGB')

        #Load mask
        mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{{img_id}}.png")
        if not os.path.exists(mask_path):
            mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{{img_id}}.jpg")
        mask = Image.open(mask_path)

        # Store original as numpy array (not PIL Image)
        img_orig = np.array(img.copy())

        #Resize
        img = img.resize((self.size, self.size), Image.BILINEAR)
        mask = mask.resize((self.size, self.size), Image.NEAREST)

        if self.transform:
            img = self.transform(img)

        mask = torch.from_numpy(np.array(mask)).long()

        return img, mask, img_orig, img_id

def compute_iou(pred, target, num_classes, ignore_index=255):
    """Compute mean IoU"""
    ious = []
    pred = pred.flatten()
    target = target.flatten()

    for cls in range(num_classes):
        pred_cls = (pred == cls)
        target_cls = (target == cls)

        # Ignore pixels marked as ignore_index
        valid = (target != ignore_index)
        pred_cls = pred_cls & valid
        target_cls = target_cls & valid

        intersection = (pred_cls & target_cls).sum()
        union = (pred_cls | target_cls).sum()

        if union == 0:
            continue

        iou = intersection.float() / union.float()
        ious.append(iou.item())

    return np.mean(ious) if ious else 0.0

def compute_all_metrics(pred, target, num_classes, ignore_index=255):
    #Compute IoU, Dice, Precision, Recall, Accuracy
    pred = pred.flatten()
    target = target.flatten()

    # Filter out ignore index
    valid_mask = (target != ignore_index)
    pred = pred[valid_mask]
    target = target[valid_mask]

    ious = []
    dices = []
    precisions = []
    recalls = []

    for cls in range(num_classes):
        pred_cls = (pred == cls)
        target_cls = (target == cls)

        #True Positives, False Positives, False Negatives
        tp = (pred_cls & target_cls).sum().float()
        fp = (pred_cls & ~target_cls).sum().float()
        fn = (~pred_cls & target_cls).sum().float()

        # IoU
        union = tp + fp + fn
        iou = tp / (union + 1e-8)
        ious.append(iou.item())

        #Dice (F1)
        dice = (2 * tp) / (2 * tp + fp + fn + 1e-8)
        dices.append(dice.item())

        #Precision
        precision = tp / (tp + fp + 1e-8)
        precisions.append(precision.item())

        #Recall
        recall = tp / (tp + fn + 1e-8)
        recalls.append(recall.item())

    # Overall Accuracy
    accuracy = (pred == target).float().mean().item()

    return {{
        'iou': ious,
        'dice': dices,
        'precision': precisions,
        'recall': recalls,
        'accuracy': accuracy,
        'mean_iou': np.mean(ious),
        'mean_dice': np.mean(dices),
        'mean_precision': np.mean(precisions),
        'mean_recall': np.mean(recalls)
    }}

#Load model
print("Loading trained model...")
model = UNetPlusPlusMobileNetV2(num_classes=NUM_CLASSES, pretrained=False)

# Find the best model file (with dice score in filename)
import glob
checkpoint_dir = 'exp/aircraft_unetpp'
checkpoint_files = glob.glob(os.path.join(checkpoint_dir, 'best_model_dice=*.pth'))

if checkpoint_files:
    # Get the file with highest dice score
    checkpoint_path = max(checkpoint_files, key=lambda x: float(x.split('dice=')[1].split('.pth')[0]))
    print(f"Found best checkpoint: {{os.path.basename(checkpoint_path)}}")
else:
    #Fallback to generic name if it exists
    checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')
    if not os.path.exists(checkpoint_path):
        print("Error: No checkpoint found!")
        print(f"Looking in: {{checkpoint_dir}}")
        import sys
        sys.exit(1)

checkpoint = torch.load(checkpoint_path, map_location=DEVICE, weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
model = model.to(DEVICE)
model.eval()

print(f"Model loaded from epoch {{checkpoint['epoch']}}")
if 'dice' in checkpoint:
    print(f"Best Dice score: {{checkpoint['dice']:.4f}}")

#Load validation dataset
val_transform = T.Compose([
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_file = os.path.join(DATA_ROOT, 'ImageSets/Segmentation/val.txt')
val_dataset = EvalDataset(DATA_ROOT, val_file, val_transform, size=512)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)

print(f"\\nEvaluating on {{len(val_dataset)}} validation images...")

# Evaluate
os.makedirs('results', exist_ok=True)
all_ious = []
all_dices = []
all_precisions = []
all_recalls = []
all_accuracies = []
all_losses = []
all_preds = []
all_targets = []

#Loss function for evaluation
criterion = torch.nn.CrossEntropyLoss(ignore_index=255)

with torch.no_grad():
    for idx, (image, mask, img_orig, img_id) in enumerate(tqdm(val_loader)):
        image = image.to(DEVICE)
        mask = mask.to(DEVICE)

        output = model(image)

        #Compute loss
        loss = criterion(output, mask)
        all_losses.append(loss.item())

        pred = output.argmax(dim=1).cpu().numpy()[0]
        mask_np = mask.cpu().numpy()[0]

        # Store for confusion matrix
        valid_mask = (mask_np != 255)
        all_preds.extend(pred[valid_mask].flatten())
        all_targets.extend(mask_np[valid_mask].flatten())

        #compute all metrics
        metrics = compute_all_metrics(torch.from_numpy(pred), torch.from_numpy(mask_np), NUM_CLASSES)
        all_ious.append(metrics['mean_iou'])
        all_dices.append(metrics['mean_dice'])
        all_precisions.append(metrics['mean_precision'])
        all_recalls.append(metrics['mean_recall'])
        all_accuracies.append(metrics['accuracy'])

        #Save visualizations for first 10 images
        if idx < 10:
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))

            # Original image
            axes[0].imshow(img_orig[0])
            axes[0].set_title('Input Image')
            axes[0].axis('off')

            axes[1].imshow(mask_np, cmap='tab20', vmin=0, vmax=NUM_CLASSES-1)
            axes[1].set_title('Ground Truth')
            axes[1].axis('off')

            axes[2].imshow(pred, cmap='tab20', vmin=0, vmax=NUM_CLASSES-1)
            axes[2].set_title(f'Prediction\\nIoU: {{metrics["mean_iou"]:.3f}} | Dice: {{metrics["mean_dice"]:.3f}}')
            axes[2].axis('off')

            plt.tight_layout()
            plt.savefig(f'results/prediction_{{idx}}.png', dpi=150, bbox_inches='tight')
            plt.close()

mean_iou = np.mean(all_ious)
mean_dice = np.mean(all_dices)
mean_precision = np.mean(all_precisions)
mean_recall = np.mean(all_recalls)
mean_accuracy = np.mean(all_accuracies)
mean_loss = np.mean(all_losses)

#Create confusion matrix
cm = confusion_matrix(all_targets, all_preds, labels=list(range(NUM_CLASSES)))

#Normalize confusion matrix for percentages
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100

#Plot confusion matrix with both counts and percentages
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
class_names = ['Background', 'Aircraft'] if NUM_CLASSES == 2 else [f'Class {{i}}' for i in range(NUM_CLASSES)]

#Confusion Matrix Raw Counts
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,
            xticklabels=class_names,
            yticklabels=class_names,
            cbar_kws={{'label': 'Count'}},
            annot_kws={{'size': 14, 'weight': 'bold'}})
ax1.set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold', pad=15)
ax1.set_ylabel('True Label', fontsize=12, fontweight='bold')
ax1.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')

# Confusion Matrix Percentages
sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Greens', ax=ax2,
            xticklabels=class_names,
            yticklabels=class_names,
            cbar_kws={{'label': 'Percentage (%)'}},
            annot_kws={{'size': 14, 'weight': 'bold'}})
ax2.set_title('Confusion Matrix (Percentages)', fontsize=14, fontweight='bold', pad=15)
ax2.set_ylabel('True Label', fontsize=12, fontweight='bold')
ax2.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')

plt.suptitle(f'Model Performance: IoU={{mean_iou:.4f}} | Dice={{mean_dice:.4f}} | Accuracy={{mean_accuracy:.4f}}',
             fontsize=16, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig('results/confusion_matrix.png', dpi=150, bbox_inches='tight')
plt.close()

print(f"\\n{{'='*70}}")
print(f"EVALUATION RESULTS")
print(f"{{'='*70}}")
print(f"\\n  Overall Metrics:")
print(f"{{'─'*70}}")
print(f"  Loss:           {{mean_loss:.4f}} (±{{np.std(all_losses):.4f}})")
print(f"  Accuracy:       {{mean_accuracy:.4f}} (±{{np.std(all_accuracies):.4f}})")
print(f"  Mean IoU:       {{mean_iou:.4f}} (±{{np.std(all_ious):.4f}})")
print(f"  Mean Dice:      {{mean_dice:.4f}} (±{{np.std(all_dices):.4f}})")
print(f"  Mean Precision: {{mean_precision:.4f}} (±{{np.std(all_precisions):.4f}})")
print(f"  Mean Recall:    {{mean_recall:.4f}} (±{{np.std(all_recalls):.4f}})")
print(f"{{'─'*70}}")
print(f"\\n Best Performance:")
print(f"{{'─'*70}}")
print(f"  Max IoU:        {{np.max(all_ious):.4f}}")
print(f"  Max Dice:       {{np.max(all_dices):.4f}}")
print(f"  Max Precision:  {{np.max(all_precisions):.4f}}")
print(f"  Max Recall:     {{np.max(all_recalls):.4f}}")
print(f"  Max Accuracy:   {{np.max(all_accuracies):.4f}}")
print(f"{{'─'*70}}")
print(f"\\n Per-Class Performance:")
print(f"{{'─'*70}}")
for i, class_name in enumerate(class_names):
    tp = cm[i, i]
    fp = cm[:, i].sum() - tp
    fn = cm[i, :].sum() - tp
    class_iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0
    class_accuracy = tp / cm[i, :].sum() if cm[i, :].sum() > 0 else 0

    print(f"\\n  {{class_name}}:")
    print(f"    True Positives:  {{tp:,}}")
    print(f"    False Positives: {{fp:,}}")
    print(f"    False Negatives: {{fn:,}}")
    print(f"    Class IoU:       {{class_iou:.4f}}")
    print(f"    Class Accuracy:  {{class_accuracy:.4f}}")
print(f"\\n{{'='*70}}")
print("\\n Evaluation Complete!")
print(f"{{'─'*70}}")
print("  Saved Files:")
print("     Predictions: results/prediction_*.png (first 10 samples)")
print("     Confusion Matrix: results/confusion_matrix.png")
print(f"{{'='*70}}")
'''

with open('/content/my_project/eval_model.py', 'w') as f:
    f.write(eval_script)

print("Created evaluation script: eval_model.py")

"""# 7. Run and Evaluate"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/my_project
!python train_semi.py

!python eval_model.py

from IPython.display import Image, display
import glob

for img_path in sorted(glob.glob('results/prediction_*.png')):
    display(Image(img_path))

"""# 9. Updated Training Script for Strong-Weak Augs

"""

#!/usr/bin/env python3

#Semi-Supervised Training with WITH STRONG-WEAK AUGMENTATION

#Implements:
# Dual stream training (labeled + unlabeled)
#Strong-weak augmentation for consistency regularization
#Pseudo-labeling with confidence thresholding
#Consistency loss between weak and strong predictions
import argparse
import os
import random
import numpy as np
import torch
from torch import nn
from torch.optim import SGD, Adam
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import torchvision.transforms as T
import albumentations as A
from albumentations.pytorch import ToTensorV2
import sys
sys.path.insert(0, '/content/my_project')
from model.semseg.unetplusplus import UNetPlusPlusMobileNetV2
import torch.nn.functional as F
from torch.cuda.amp import autocast, GradScaler

DATA_ROOT = "/content/drive/MyDrive/aircraft_voc"
NUM_CLASSES = 2

#simple logger and utility classes
class SimpleLogger:
    def __init__(self, name):
        self.name = name
    def info(self, msg):
        print(f"[INFO] {msg}")

class AverageMeter:
    """Computes and stores the average and current value"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

def dice_loss(preds, targets, smooth=1e-6):
    """Dice loss for binary segmentation"""
    probs = torch.softmax(preds, dim=1)[:, 1, :, :]
    targets = (targets == 1).float()

    probs = probs.contiguous().view(-1)
    targets = targets.contiguous().view(-1)

    intersection = (probs * targets).sum()
    dice = (2. * intersection + smooth) / (probs.sum() + targets.sum() + smooth)
    return 1 - dice

def compute_metrics(pred, target, num_classes=2, ignore_index=255):
    """Compute IoU, Dice, Accuracy, Precision, Recall"""
    pred = pred.flatten()
    target = target.flatten()

    valid_mask = (target != ignore_index)
    pred = pred[valid_mask]
    target = target[valid_mask]

    metrics = {}

    ious = []
    dices = []
    precisions = []
    recalls = []

    for cls in range(num_classes):
        pred_cls = (pred == cls)
        target_cls = (target == cls)

        tp = (pred_cls & target_cls).sum().float()
        fp = (pred_cls & ~target_cls).sum().float()
        fn = (~pred_cls & target_cls).sum().float()

        union = tp + fp + fn
        iou = tp / (union + 1e-8)
        ious.append(iou.item())

        dice = (2 * tp) / (2 * tp + fp + fn + 1e-8)
        dices.append(dice.item())

        precision = tp / (tp + fp + 1e-8)
        precisions.append(precision.item())

        recall = tp / (tp + fn + 1e-8)
        recalls.append(recall.item())

    accuracy = (pred == target).float().mean().item()

    metrics['iou'] = np.mean(ious)
    metrics['dice'] = np.mean(dices)
    metrics['accuracy'] = accuracy
    metrics['precision'] = np.mean(precisions)
    metrics['recall'] = np.mean(recalls)

    return metrics

def validate(model, dataloader, device, num_classes):
    """Validation function with all metrics"""
    model.eval()
    all_metrics = {'iou': [], 'dice': [], 'accuracy': [], 'precision': [], 'recall': []}

    with torch.no_grad():
        for images, masks in dataloader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            preds = outputs.argmax(dim=1)

            batch_metrics = compute_metrics(preds, masks, num_classes)
            for k in all_metrics:
                all_metrics[k].append(batch_metrics[k])

    return {k: np.mean(v) for k, v in all_metrics.items()}

def parse_args():
    parser = argparse.ArgumentParser(description='Semi-Supervised Semantic Segmentation')
    parser.add_argument('--config', type=str, default='configs/aircraft.yaml')
    parser.add_argument('--labeled-id-path', type=str, default='splits/aircraft/labeled.txt')
    parser.add_argument('--unlabeled-id-path', type=str, default='splits/aircraft/unlabeled.txt')
    parser.add_argument('--save-path', type=str, default='exp/aircraft_my_project_strong_weak')
    parser.add_argument('--local_rank', type=int, default=0)
    parser.add_argument('--port', default=None, type=int)
    args = parser.parse_args([])
    return args

def create_split_files(data_root, labeled_ratio=0.1):
    """Create labeled/unlabeled splits for semi-supervised learning"""
    train_file = os.path.join(data_root, 'ImageSets/Segmentation/train.txt')
    if not os.path.exists(train_file):
        train_file = os.path.join(data_root, 'ImageSets/Segmentation/trainval.txt')
        if not os.path.exists(train_file):
            print(f"Error: Neither train.txt nor trainval.txt found in {data_root}/ImageSets/Segmentation/")
            return False

    with open(train_file, 'r') as f:
        all_ids = [line.strip() for line in f.readlines()]

    if len(all_ids) == 0:
        print("Error: No image IDs found in train file!")
        return False

    random.shuffle(all_ids)
    num_labeled = max(1, int(len(all_ids) * labeled_ratio))
    labeled_ids = all_ids[:num_labeled]
    unlabeled_ids = all_ids[num_labeled:]

    os.makedirs('splits/aircraft', exist_ok=True)

    with open('splits/aircraft/labeled.txt', 'w') as f:
        f.write('\n'.join(labeled_ids))

    with open('splits/aircraft/unlabeled.txt', 'w') as f:
        f.write('\n'.join(unlabeled_ids))

    print(f" Created splits: {num_labeled} labeled, {len(unlabeled_ids)} unlabeled")
    print(f"  Labeled ratio: {labeled_ratio*100:.1f}%")
    return True

def get_default_config():
    """Default configuration for training"""
    return {
        'dataset': 'aircraft',
        'data_root': DATA_ROOT,
        'batch_size': 4,
        'lr': 0.0005,
        'min_lr': 0.000001,
        'epochs': 40,
        'crop_size': 512,
        'backbone': 'unetplusplus',
        'num_classes': NUM_CLASSES,
        # Semi-supervised settings
        'labeled_ratio': 0.7,
        'unsup_weight': 1.0,
        'consistency_weight': 1.0,  # NEW: Weight for consistency loss
        'pseudo_threshold': 0.95,
        'use_strong_aug': True,
        # Optimizer
        'optimizer': 'adam',
        'momentum': 0.9,
        'weight_decay': 0,
        'lr_decay_type': 'cos',
        # Training settings
        'num_workers': 4,
        'mixed_precision': True,
        'sync_bn': True,
        # Early stopping
        'early_stopping': True,
        'patience': 10,
        'monitor': 'val_dice',
        # Logging
        'print_interval': 10,
        'eval_interval': 1,
        'save_period': 20,
    }

# NEW WEAK AUGMENTATION DATASET
class WeakAugDataset(Dataset):
    def __init__(self, data_root, split_file, size=512):
        self.data_root = data_root
        self.size = size

        with open(split_file, 'r') as f:
            self.ids = [line.strip() for line in f.readlines()]

        # WEAK augmentation minimal transforms
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]

        self.transform = A.Compose([
            A.HorizontalFlip(p=0.5),  #only horizontal flip
            A.Resize(size, size),
            A.Normalize(mean=mean, std=std),
            ToTensorV2()
        ])

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        img_id = self.ids[idx]

        #load image
        img_path = os.path.join(self.data_root, 'JPEGImages', f"{img_id}.jpg")
        if not os.path.exists(img_path):
            img_path = os.path.join(self.data_root, 'JPEGImages', f"{img_id}.png")
        img = Image.open(img_path).convert('RGB')

        mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{img_id}.png")
        if not os.path.exists(mask_path):
            mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{img_id}.jpg")
        mask = Image.open(mask_path)

        #resize first
        img = img.resize((self.size, self.size), Image.BILINEAR)
        mask = mask.resize((self.size, self.size), Image.NEAREST)

        img = np.array(img)
        mask = np.array(mask)

        #apply weak augmentations
        augmented = self.transform(image=img, mask=mask)
        img = augmented['image']
        mask = augmented['mask'].long()

        return img, mask

# NEW STRONG AUGMENTATION DATASET
class StrongAugDataset(Dataset):

    def __init__(self, data_root, split_file, size=512):
        self.data_root = data_root
        self.size = size

        with open(split_file, 'r') as f:
            self.ids = [line.strip() for line in f.readlines()]

        # STRONG augmentation aggressive transforms
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]

        self.transform = A.Compose([
            #Geometric augmentations
            A.RandomScale(scale_limit=0.5, p=0.7),
            A.Rotate(limit=20, p=0.7),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),
            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),

            #Color augmentations (applied only to image, not mask)
            A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=0.6),
            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),
            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),

            #Noise and blur
            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
            A.GaussianBlur(blur_limit=(3, 7), p=0.3),

            #Dropout/Erasing
            A.CoarseDropout(
                max_holes=8,
                max_height=32,
                max_width=32,
                min_holes=3,
                min_height=8,
                min_width=8,
                fill_value=0,
                p=0.4
            ),

            A.Resize(size, size),
            A.Normalize(mean=mean, std=std),
            ToTensorV2()
        ])

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        img_id = self.ids[idx]

        #Load image
        img_path = os.path.join(self.data_root, 'JPEGImages', f"{img_id}.jpg")
        if not os.path.exists(img_path):
            img_path = os.path.join(self.data_root, 'JPEGImages', f"{img_id}.png")
        img = Image.open(img_path).convert('RGB')

        #Load mask
        mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{img_id}.png")
        if not os.path.exists(mask_path):
            mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{img_id}.jpg")
        mask = Image.open(mask_path)

        # Resize
        img = img.resize((self.size, self.size), Image.BILINEAR)
        mask = mask.resize((self.size, self.size), Image.NEAREST)

        img = np.array(img)
        mask = np.array(mask)

        # Apply STRONG augmentations
        augmented = self.transform(image=img, mask=mask)
        img = augmented['image']
        mask = augmented['mask'].long()

        return img, mask

# LABELED DATA DATASET (moderate augmentation)
class LabeledDataset(Dataset):
    def __init__(self, data_root, split_file, size=512):
        self.data_root = data_root
        self.size = size

        with open(split_file, 'r') as f:
            self.ids = [line.strip() for line in f.readlines()]

        # augmentation for labeled data
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]

        self.transform = A.Compose([
            A.RandomScale(scale_limit=0.5, p=0.5),
            A.Rotate(limit=10, p=0.5),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),
            A.Resize(size, size),
            A.Normalize(mean=mean, std=std),
            ToTensorV2()
        ])

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        img_id = self.ids[idx]

        # Load image
        img_path = os.path.join(self.data_root, 'JPEGImages', f"{img_id}.jpg")
        if not os.path.exists(img_path):
            img_path = os.path.join(self.data_root, 'JPEGImages', f"{img_id}.png")
        img = Image.open(img_path).convert('RGB')

        # Load mask
        mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{img_id}.png")
        if not os.path.exists(mask_path):
            mask_path = os.path.join(self.data_root, 'SegmentationClass', f"{img_id}.jpg")
        mask = Image.open(mask_path)

        #Resize first
        img = img.resize((self.size, self.size), Image.BILINEAR)
        mask = mask.resize((self.size, self.size), Image.NEAREST)

        img = np.array(img)
        mask = np.array(mask)

        augmented = self.transform(image=img, mask=mask)
        img = augmented['image']
        mask = augmented['mask'].long()

        return img, mask

def main():
    args = parse_args()
    cfg = get_default_config()

    # logging
    os.makedirs(args.save_path, exist_ok=True)
    logger = SimpleLogger('global')

    #Set random seed
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)
    torch.cuda.manual_seed_all(42)

    #Create labeled/unlabeled splits
    print("\n" + "="*80)
    print("STRONG-WEAK AUGMENTATION SEMI-SUPERVISED LEARNING")
    print("="*80)
    print("\nCreating semi-supervised data splits...")
    if not create_split_files(DATA_ROOT, labeled_ratio=cfg['labeled_ratio']):
        print("Error creating splits!")
        return

    #Device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nUsing device: {device}")

    #Create model
    print("\nCreating UNet++ model with MobileNetV2 encoder...")
    model = UNetPlusPlusMobileNetV2(num_classes=NUM_CLASSES, pretrained=True)
    model = model.to(device)

    # Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    print(f"  Total parameters: {total_params:,}")

    # Optimizer
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=cfg['lr'],
        weight_decay=cfg['weight_decay']
    )

    # Learning rate scheduler
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer,
        T_max=cfg['epochs'],
        eta_min=cfg['min_lr']
    )

    # Loss functions
    criterion_ce = nn.CrossEntropyLoss(ignore_index=255).to(device)
    criterion_u = nn.CrossEntropyLoss(ignore_index=255, reduction='none').to(device)

    # Mixed precision training scaler
    scaler = GradScaler() if cfg['mixed_precision'] else None

    # ========================================================================
    print(f"\nLoading datasets from {DATA_ROOT}...")
    print("\n Dataset Configuration:")
    print("   Labeled data: Moderate augmentation")
    print("  Unlabeled (WEAK): Minimal augmentation → Generate pseudo-labels")
    print("  Unlabeled (STRONG): Aggressive augmentation → Consistency training")
    print()

    # Labeled dataset with moderate augmentation
    trainset_l = LabeledDataset(DATA_ROOT, 'splits/aircraft/labeled.txt', size=cfg['crop_size'])

    # Unlabeled dataset with WEAK augmentation (for pseudo-labels)
    trainset_u_weak = WeakAugDataset(DATA_ROOT, 'splits/aircraft/unlabeled.txt', size=cfg['crop_size'])

    # Unlabeled dataset with STRONG augmentation (for consistency)
    trainset_u_strong = StrongAugDataset(DATA_ROOT, 'splits/aircraft/unlabeled.txt', size=cfg['crop_size'])

    # Data loaders
    trainloader_l = DataLoader(trainset_l, batch_size=cfg['batch_size'],
                               shuffle=True, num_workers=cfg['num_workers'], drop_last=True, pin_memory=True)

    trainloader_u_weak = DataLoader(trainset_u_weak, batch_size=cfg['batch_size'],
                                    shuffle=True, num_workers=cfg['num_workers'], drop_last=True, pin_memory=True)

    trainloader_u_strong = DataLoader(trainset_u_strong, batch_size=cfg['batch_size'],
                                      shuffle=True, num_workers=cfg['num_workers'], drop_last=True, pin_memory=True)

    print(f"  Labeled samples: {len(trainset_l)}")
    print(f"  Unlabeled samples: {len(trainset_u_weak)}")

    # Training loop
    print(f"\nStarting semi-supervised training for {cfg['epochs']} epochs...")
    print(f"Mixed Precision: {cfg['mixed_precision']}")
    print(f"Early Stopping: {cfg['early_stopping']} (patience={cfg['patience']})")
    print(f"Consistency Weight: {cfg['consistency_weight']}")
    print("=" * 80)

    best_loss = float('inf')
    best_dice = 0.0
    patience_counter = 0

    for epoch in range(cfg['epochs']):
        model.train()
        losses_l = AverageMeter()
        losses_u = AverageMeter()
        losses_consistency = AverageMeter()
        losses_total = AverageMeter()

        #Create iterators
        loader_l_iter = iter(trainloader_l)
        loader_u_weak_iter = iter(trainloader_u_weak)
        loader_u_strong_iter = iter(trainloader_u_strong)

        num_batches = min(len(trainloader_l), len(trainloader_u_weak))

        for i in range(num_batches):
            #Get labeled batch
            try:
                img_l, mask_l = next(loader_l_iter)
            except StopIteration:
                loader_l_iter = iter(trainloader_l)
                img_l, mask_l = next(loader_l_iter)

            # Get unlabeled batch with WEAK augmentation
            try:
                img_u_weak, _ = next(loader_u_weak_iter)
            except StopIteration:
                loader_u_weak_iter = iter(trainloader_u_weak)
                img_u_weak, _ = next(loader_u_weak_iter)

            # Get unlabeled batch with STRONG augmentation
            try:
                img_u_strong, _ = next(loader_u_strong_iter)
            except StopIteration:
                loader_u_strong_iter = iter(trainloader_u_strong)
                img_u_strong, _ = next(loader_u_strong_iter)

            img_l, mask_l = img_l.to(device), mask_l.to(device)
            img_u_weak = img_u_weak.to(device)
            img_u_strong = img_u_strong.to(device)

            optimizer.zero_grad()

            #Mixed precision training
            if cfg['mixed_precision']:
                with autocast():
                    # 1. Supervised loss on labeled data
                    pred_l = model(img_l)
                    ce_loss = criterion_ce(pred_l, mask_l)
                    d_loss = dice_loss(pred_l, mask_l)
                    loss_l = ce_loss + 0.5 * d_loss

                    # 2. Generate pseudo-labels from WEAK augmentation
                    with torch.no_grad():
                        pred_u_weak = model(img_u_weak)
                        prob_u_weak = F.softmax(pred_u_weak, dim=1)
                        conf_u, pseudo_u = torch.max(prob_u_weak, dim=1)

                        # Confidence mask
                        mask_u = (conf_u >= cfg['pseudo_threshold']).float()

                    # 3. Pseudo-label loss on STRONG augmentation
                    pred_u_strong = model(img_u_strong)
                    loss_u = criterion_u(pred_u_strong, pseudo_u)
                    loss_u = (loss_u * mask_u).sum() / (mask_u.sum() + 1e-8)

                    # 4. Consistency loss between weak and strong
                    # Get predictions on strong augmentation
                    prob_u_strong = F.softmax(pred_u_strong, dim=1)

                    # Consistency loss: KL divergence between weak and strong predictions
                    consistency_loss = F.kl_div(
                        F.log_softmax(pred_u_strong, dim=1),
                        prob_u_weak.detach(),
                        reduction='none'
                    ).sum(dim=1)

                    # Apply confidence mask
                    consistency_loss = (consistency_loss * mask_u).sum() / (mask_u.sum() + 1e-8)

                    # 5. Total loss
                    loss = loss_l + \
                           cfg['unsup_weight'] * loss_u + \
                           cfg['consistency_weight'] * consistency_loss

                # Backward with gradient scaling
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()

            else:
                # Standard training (no mixed precision)
                # 1. Supervised loss
                pred_l = model(img_l)
                ce_loss = criterion_ce(pred_l, mask_l)
                d_loss = dice_loss(pred_l, mask_l)
                loss_l = ce_loss + 0.5 * d_loss

                # 2. Generate pseudo-labels from weak
                with torch.no_grad():
                    pred_u_weak = model(img_u_weak)
                    prob_u_weak = F.softmax(pred_u_weak, dim=1)
                    conf_u, pseudo_u = torch.max(prob_u_weak, dim=1)
                    mask_u = (conf_u >= cfg['pseudo_threshold']).float()

                # 3. Pseudo-label loss on strong
                pred_u_strong = model(img_u_strong)
                loss_u = criterion_u(pred_u_strong, pseudo_u)
                loss_u = (loss_u * mask_u).sum() / (mask_u.sum() + 1e-8)

                # 4. Consistency loss
                prob_u_strong = F.softmax(pred_u_strong, dim=1)
                consistency_loss = F.kl_div(
                    F.log_softmax(pred_u_strong, dim=1),
                    prob_u_weak.detach(),
                    reduction='none'
                ).sum(dim=1)
                consistency_loss = (consistency_loss * mask_u).sum() / (mask_u.sum() + 1e-8)

                # 5. Total loss
                loss = loss_l + cfg['unsup_weight'] * loss_u + cfg['consistency_weight'] * consistency_loss

                loss.backward()
                optimizer.step()

            # Update metrics
            losses_l.update(loss_l.item())
            losses_u.update(loss_u.item())
            losses_consistency.update(consistency_loss.item())
            losses_total.update(loss.item())

            if (i + 1) % cfg['print_interval'] == 0:
                print(f"Epoch [{epoch+1}/{cfg['epochs']}] "
                      f"Iter [{i+1}/{num_batches}] "
                      f"Loss: {losses_total.avg:.4f} "
                      f"(L: {losses_l.avg:.4f}, U: {losses_u.avg:.4f}, C: {losses_consistency.avg:.4f})")

        #Validation phase
        if (epoch + 1) % cfg['eval_interval'] == 0:
            model.eval()
            val_metrics = validate(model, trainloader_l, device, cfg['num_classes'])
            model.train()

            print(f"\nEpoch {epoch+1} completed:")
            print(f"  Train Loss: {losses_total.avg:.4f} (Labeled: {losses_l.avg:.4f}, Unlabeled: {losses_u.avg:.4f}, Consistency: {losses_consistency.avg:.4f})")
            print(f"  Val IoU: {val_metrics['iou']:.4f}")
            print(f"  Val Dice: {val_metrics['dice']:.4f}")
            print(f"  Val Accuracy: {val_metrics['accuracy']:.4f}")
            print(f"  Val Precision: {val_metrics['precision']:.4f}")
            print(f"  Val Recall: {val_metrics['recall']:.4f}")
            print(f"  Learning Rate: {optimizer.param_groups[0]['lr']:.6f}")

            # Save best model based on dice score
            if val_metrics['dice'] > best_dice:
                best_dice = val_metrics['dice']
                patience_counter = 0
                checkpoint = {
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'dice': best_dice,
                    'loss': losses_total.avg,
                }
                torch.save(checkpoint, os.path.join(args.save_path, f'best_model_dice={best_dice:.2f}.pth'))
                print(f"  Saved best model (dice: {best_dice:.4f})")
            else:
                patience_counter += 1
                print(f"  No improvement (patience: {patience_counter}/{cfg['patience']})")

            # Early stopping
            if cfg['early_stopping'] and patience_counter >= cfg['patience']:
                print(f"\n  Early stopping triggered! No improvement for {cfg['patience']} epochs.")
                break

        # Step the learning rate scheduler
        scheduler.step()

        # Periodic checkpoint saving
        if (epoch + 1) % cfg['save_period'] == 0:
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'loss': losses_total.avg,
            }
            torch.save(checkpoint, os.path.join(args.save_path, f'epoch_{epoch+1}.pth'))
            print(f"   Saved periodic checkpoint: epoch_{epoch+1}.pth")

        print("=" * 80)

    print("\n Training complete!")
    print(f"Best dice: {best_dice:.4f}")
    print(f"Model saved to: {args.save_path}/best_model_dice={best_dice:.2f}.pth")

if __name__ == '__main__':
    main()

"""# 10. Visualization of Strong-Weak Augs"""

#!/usr/bin/env python3
#Visualize the difference between WEAK and STRONG augmentations to see what the model sees during training
import os
import sys
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2

DATA_ROOT = "/content/drive/MyDrive/aircraft_voc"

# Read a sample image
train_file = os.path.join(DATA_ROOT, 'ImageSets/Segmentation/train.txt')
if not os.path.exists(train_file):
    train_file = os.path.join(DATA_ROOT, 'ImageSets/Segmentation/trainval.txt')

with open(train_file, 'r') as f:
    sample_id = f.readline().strip()

img_path = os.path.join(DATA_ROOT, 'JPEGImages', f"{sample_id}.jpg")
if not os.path.exists(img_path):
    img_path = os.path.join(DATA_ROOT, 'JPEGImages', f"{sample_id}.png")

img = Image.open(img_path).convert('RGB')
img = img.resize((512, 512), Image.BILINEAR)
img_np = np.array(img)

#weak augs
weak_transform = A.Compose([
    A.HorizontalFlip(p=1.0),
    A.Resize(512, 512),
])

#strong augs
strong_transform = A.Compose([
    A.RandomScale(scale_limit=0.5, p=1.0),
    A.Rotate(limit=20, p=1.0),
    A.HorizontalFlip(p=1.0),
    A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1, p=1.0),
    A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),
    A.CoarseDropout(
        max_holes=8,
        max_height=32,
        max_width=32,
        min_holes=3,
        min_height=8,
        min_width=8,
        fill_value=0,
        p=1.0
    ),
    A.Resize(512, 512),
])

#apply transformations
weak_aug = weak_transform(image=img_np)['image']
strong_aug = strong_transform(image=img_np)['image']

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

axes[0].imshow(img_np)
axes[0].set_title('Original Image', fontsize=14, fontweight='bold')
axes[0].axis('off')

axes[1].imshow(weak_aug)
axes[1].set_title('WEAK Augmentation\n(For Pseudo-Labels)\n\n• Horizontal Flip\n• Minimal Changes',
                  fontsize=14, fontweight='bold', color='green')
axes[1].axis('off')

axes[2].imshow(strong_aug)
axes[2].set_title('STRONG Augmentation\n(For Consistency Learning)\n\n• Geometric Transforms\n• Color Jitter\n• Noise\n• Dropout',
                  fontsize=14, fontweight='bold', color='red')
axes[2].axis('off')

plt.suptitle('Strong-Weak Augmentation Strategy in Semi-Supervised Learning',
             fontsize=16, fontweight='bold', y=1.02)
plt.tight_layout()
plt.savefig('augmentation_comparison.png', dpi=150, bbox_inches='tight')
plt.close()

print(" Visualization saved to: augmentation_comparison.png")

fig, axes = plt.subplots(3, 3, figsize=(15, 15))

for i in range(3):
    #generate different strong augmentations
    strong_aug1 = strong_transform(image=img_np)['image']
    strong_aug2 = strong_transform(image=img_np)['image']
    strong_aug3 = strong_transform(image=img_np)['image']

    axes[i, 0].imshow(strong_aug1)
    axes[i, 0].set_title(f'Strong Aug Sample {i+1}A', fontweight='bold')
    axes[i, 0].axis('off')

    axes[i, 1].imshow(strong_aug2)
    axes[i, 1].set_title(f'Strong Aug Sample {i+1}B', fontweight='bold')
    axes[i, 1].axis('off')

    axes[i, 2].imshow(strong_aug3)
    axes[i, 2].set_title(f'Strong Aug Sample {i+1}C', fontweight='bold')
    axes[i, 2].axis('off')

plt.suptitle('Diversity of Strong Augmentations\n(Same image, different random transforms)',
             fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('strong_augmentation_diversity.png', dpi=150, bbox_inches='tight')
plt.close()

print(" Diversity visualization saved to: strong_augmentation_diversity.png")

"""#11. Evaluation (same as earlier)"""

!python eval_model.py
