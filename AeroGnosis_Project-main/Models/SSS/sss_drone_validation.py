# -*- coding: utf-8 -*-
"""SSS_drone_validation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qkDJwSp0SNSJ5xzcZnS8St0pvZ3PwgKG
"""

# mounting google drive
from google.colab import drive
drive.mount('/content/drive')

# installing dependencies
!pip install -q torch torchvision
!pip install -q segmentation-models-pytorch
!pip install -q tensorboard
!pip install -q pyyaml
!pip install -q opencv-python
!pip install -q matplotlib
import os

DATA_ROOT = '/content/Drone_val_images'
NUM_CLASSES = 2

#!/usr/bin/env python3

import os
import torch
import torch.nn as nn
import numpy as np
from PIL import Image as PilImage

# installing segmentation_models_pytorch if not already installed (this is runtime)
try:
    import segmentation_models_pytorch as smp
except ImportError:
    print("Installing segmentation_models_pytorch...")
    !pip install -q segmentation-models-pytorch
    import segmentation_models_pytorch as smp

import cv2
import matplotlib.pyplot as plt
from scipy.ndimage import distance_transform_edt
from skimage.morphology import skeletonize as ski_skeletonize

# unet++ model setup

class UNetPlusPlus(nn.Module):
    # unet++ with mobilenetv2 encoder for crack segmentation

    def __init__(self, num_classes, encoder_name='mobilenet_v2', pretrained=False):
        super(UNetPlusPlus, self).__init__()

        self.num_classes = num_classes
        self.encoder_name = encoder_name

        # build unet++ with mobilenetv2 encoder pretrained on imagenet
        self.backbone = smp.UnetPlusPlus(
            encoder_name=encoder_name,
            encoder_weights='imagenet' if pretrained else None,
            in_channels=3,
            classes=num_classes,
            activation=None,  # no activation, just raw logits
        )

    def forward(self, x, need_fp=False):
        # forward pass
        out = self.backbone(x)
        if need_fp:
            return out, out
        return out

# crack measurement functions

def calculate_crack_length(skeleton, px_to_mm=0.077):
    # figure out total crack length by adding up distances between skeleton points

    # grab all skeleton pixel coordinates
    skel_coords = np.column_stack(np.where(skeleton))

    if len(skel_coords) < 2:
        return 0.0

    # add up distances between consecutive points
    total_length_px = 0.0
    for i in range(len(skel_coords) - 1):
        p1 = skel_coords[i]
        p2 = skel_coords[i + 1]
        dist = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)
        total_length_px += dist

    # convert pixels to mm
    return total_length_px * px_to_mm


def measure_crack_width_from_binary(binary_mask, skeleton, px_to_mm=0.077, visualize=False):
    # measure crack width using distance transform
    # basically: width at each point = 2x distance to nearest edge

    mask = (binary_mask > 0).astype(np.uint8)

    # distance transform tells us how far each point is from the background
    distance_map = distance_transform_edt(mask)
    skel_coords = np.column_stack(np.where(skeleton))

    if len(skel_coords) == 0:
        return 0.0, 0.0, np.array([])

    # check width at each skeleton point
    widths_px = []
    for y, x in skel_coords:
        width = distance_map[y, x] * 2  # times 2 for full width
        widths_px.append(width)

    width_array_px = np.array(widths_px)

    if len(width_array_px) == 0:
        return 0.0, 0.0, width_array_px

    # convert to mm and get max/mean
    max_width_mm = np.max(width_array_px) * px_to_mm
    mean_width_mm = np.mean(width_array_px) * px_to_mm

    return max_width_mm, mean_width_mm, width_array_px * px_to_mm


def quantify_crack_complete(binary_mask, px_to_mm=0.077, method='distance_transform', visualize=True, image_path=None):
    # full crack analysis: length, width, and optional visualization

    mask = (binary_mask > 0).astype(np.uint8)

    # get the 1-pixel wide centerline of the crack
    skeleton = ski_skeletonize(mask.astype(bool))

    if skeleton.sum() == 0:
        print("empty skeleton - no crack found!")
        return {
            'length_mm': 0.0,
            'max_width_mm': 0.0,
            'mean_width_mm': 0.0,
            'skeleton': skeleton,
            'width_array': np.array([])
        }

    # measure everything
    length_mm = calculate_crack_length(skeleton, px_to_mm)
    max_width_mm, mean_width_mm, width_array = measure_crack_width_from_binary(
        mask, skeleton, px_to_mm, visualize=False
    )

    # show results if you want
    if visualize:
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # show the binary mask
        axes[0].imshow(mask, cmap='gray')
        axes[0].set_title('binary crack mask')
        axes[0].axis('off')

        # show skeleton on top of mask
        overlay = np.stack([mask * 255] * 3, axis=-1).astype(np.uint8)
        skel_coords = np.column_stack(np.where(skeleton))
        for y, x in skel_coords:
            cv2.circle(overlay, (int(x), int(y)), 1, (255, 0, 0), -1)  # red dots

        axes[1].imshow(overlay)
        axes[1].set_title(f'skeleton overlay\nlength: {length_mm:.2f} mm')
        axes[1].axis('off')

        # show distance transform with width info
        distance_map = distance_transform_edt(mask)
        im = axes[2].imshow(distance_map, cmap='hot')
        axes[2].contour(skeleton, colors='blue', linewidths=1)
        axes[2].set_title(f'distance transform\nmax width: {max_width_mm:.2f} mm\nmean width: {mean_width_mm:.2f} mm')
        axes[2].axis('off')
        plt.colorbar(im, ax=axes[2], label='distance (pixels)')

        plt.tight_layout()
        plt.show()

    return {
        'length_mm': length_mm,
        'max_width_mm': max_width_mm,
        'mean_width_mm': mean_width_mm,
        'skeleton': skeleton,
        'width_array': width_array,
        'method': method
    }


# model loading and prediction stuff

def load_model(checkpoint_path, num_classes=2, device='cuda'):
    # load the trained model from a checkpoint file
    # handles different checkpoint formats and cleans up key names

    print(f"loading checkpoint: {checkpoint_path}")

    # set up the model structure
    model = UNetPlusPlus(num_classes=num_classes, encoder_name='mobilenet_v2', pretrained=False)

    # load the checkpoint (weights_only=False since we trust this file)
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)

    # grab the weights from wherever they are in the checkpoint
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
    elif 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint

    # remove 'module.' prefix if it exists (happens with distributed training)
    new_state_dict = {}
    for key, value in state_dict.items():
        new_key = key.replace('module.', '')
        new_state_dict[new_key] = value

    # load the weights
    model.load_state_dict(new_state_dict, strict=False)
    model.to(device)
    model.eval()

    print(f"model loaded!")
    return model


def predict(model, image_path, device='cuda'):
    # run the model on an image
    # resizes to 512x512 for the model, then back to original size for accurate measurements

    import cv2

    # load the image
    image = PilImage.open(image_path).convert('RGB')
    original_size = image.size  # save original (width, height)

    # resize to 512x512 like we did in training
    image_512 = image.resize((512, 512), PilImage.BILINEAR)
    image_np_512 = np.array(image_512)

    # normalize with imagenet values (same as training)
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image_normalized = (image_np_512 / 255.0 - mean) / std

    # convert to tensor format [batch, channels, height, width]
    image_tensor = torch.from_numpy(image_normalized).float()
    image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0).to(device)

    # run the model
    with torch.no_grad():
        logits = model(image_tensor)
        pred = torch.argmax(logits, dim=1)  # turn logits into class predictions

    # get the prediction mask (512x512)
    pred_mask_512 = pred.squeeze().cpu().numpy()

    # resize back to original size for accurate pixel measurements
    pred_mask_original = cv2.resize(
        pred_mask_512.astype(np.uint8),
        original_size,  # back to original size
        interpolation=cv2.INTER_NEAREST  # keeps it binary (0s and 1s)
    )

    # return prediction at original size + the 512 version for viz
    return pred_mask_original, np.array(image_512)

model = load_model('/content/best_model_dice=0.91.pth', num_classes=2, device='cuda')

# validating on crack image 1

image_path = '/content/crack3.png'

pixel_mm = 0.222

pred_mask, og_image = predict(model, image_path=image_path, device='cuda')

# binary mask
binary_mask = (pred_mask == 1).astype(np.uint8)

# quantifying
results = quantify_crack_complete(binary_mask, px_to_mm=pixel_mm, method='edge_based',visualize=True, image_path=image_path)

print(f"\n{'='*60}")
print("RESULTS - IMAGE 1")
print(f"{'='*60}")
print(f"Length:      {results['length_mm']:.2f} mm")
print(f"Max Width:   {results['max_width_mm']:.2f} mm")
print(f"Mean Width:  {results['mean_width_mm']:.2f} mm")
print(f"{'='*60}")

# validating on crack image 2

image_path_2 = '/content/crack_image2.png'
pixel_mm_2 = 0.143


pred_mask_2, og_image_2 = predict(model, image_path=image_path_2, device='cuda')
binary_mask_2 = (pred_mask_2 == 1).astype(np.uint8)

results_2 = quantify_crack_complete(binary_mask_2, px_to_mm=pixel_mm_2, method='edge_based',visualize=True, image_path=image_path_2)

print(f"\n{'='*60}")
print("RESULTS - IMAGE 2")
print(f"{'='*60}")
print(f"Length:      {results_2['length_mm']:.2f} mm")
print(f"Max Width:   {results_2['max_width_mm']:.2f} mm")
print(f"Mean Width:  {results_2['mean_width_mm']:.2f} mm")
print(f"{'='*60}")

# error analysis

# ground truth measurements
gt_measurements = {
    'image_1': {
        'length_mm': 18.58,
        'max_width_mm': 4.4
    },
    'image_2': {
        'length_mm': 37.53,
        'max_width_mm': 3.7
    }
}

# calculate errors
length_error_1 = abs(results['length_mm'] - gt_measurements['image_1']['length_mm'])
width_error_1 = abs(results['max_width_mm'] - gt_measurements['image_1']['max_width_mm'])

length_error_2 = abs(results_2['length_mm'] - gt_measurements['image_2']['length_mm'])
width_error_2 = abs(results_2['max_width_mm'] - gt_measurements['image_2']['max_width_mm'])

# display
print("\nimage 1:")
print(f"  length error:      {length_error_1:.2f} mm")
print(f"  max width error:   {width_error_1:.2f} mm")

print("\nimage 2:")
print(f"  length error:      {length_error_2:.2f} mm")
print(f"  max width error:   {width_error_2:.2f} mm")